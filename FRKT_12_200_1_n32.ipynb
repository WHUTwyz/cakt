{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Data Preparation\n",
    "\n",
    "Before we process the data, we need to first acquire the dataset which is shown in [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "This notebook show the experiment that use the improved rasch embedding:  \n",
    "Dataset:Assistment2012  \n",
    "use_rasch:True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def generate_q_matrix(path, n_skill, n_exercise):\n",
    "    with open(path, 'rb') as f:\n",
    "        problem2skill = pickle.load(f)\n",
    "        \n",
    "    q_matrix = np.zeros((n_exercise + 1, n_skill + 1))\n",
    "    for p,values in problem2skill.items():\n",
    "        for s in values:\n",
    "            q_matrix[p][s] = 1\n",
    "    return q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_exercise = 53091\n",
    "n_skill = 265 \n",
    "batch_size = 32\n",
    "hidden_size = 128\n",
    "k_components = 32\n",
    "dropout = 0.2\n",
    "use_rasch = True\n",
    "path = \"../../data/2012-2013-data-with-predictions-4-final/problem2skill.pickle\"\n",
    "q_matrix =  generate_q_matrix(path,n_skill,n_exercise)\n",
    "dataset_name = \"assistment2012\"\n",
    "seq_len = 200\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/2012-2013-data-with-predictions-4-final/train0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [05:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 0.532132, auc: 0.742782, accuracy: 0.736284 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:24<00:00,  6.49it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] LogisticLoss: 0.508703, auc: 0.763761, accuracy: 0.754762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:54<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] LogisticLoss: 0.505301, auc: 0.775854, accuracy: 0.755792 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.82it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] LogisticLoss: 0.502245, auc: 0.771840, accuracy: 0.757481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:59<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] LogisticLoss: 0.497794, auc: 0.784429, accuracy: 0.760458 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.89it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] LogisticLoss: 0.499759, auc: 0.774782, accuracy: 0.760206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:57<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] LogisticLoss: 0.493400, auc: 0.789318, accuracy: 0.762975 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  7.04it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] LogisticLoss: 0.500770, auc: 0.775291, accuracy: 0.759078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:58<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] LogisticLoss: 0.490022, auc: 0.792898, accuracy: 0.765236 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:21<00:00,  7.45it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] LogisticLoss: 0.498908, auc: 0.776497, accuracy: 0.760972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:55<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] LogisticLoss: 0.486672, auc: 0.796400, accuracy: 0.766865 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.81it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] LogisticLoss: 0.498501, auc: 0.776710, accuracy: 0.760096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:46<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] LogisticLoss: 0.482807, auc: 0.800421, accuracy: 0.769396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:24<00:00,  6.61it/s]\n",
      "INFO:root:save parameters to saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] LogisticLoss: 0.499475, auc: 0.777226, accuracy: 0.758998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [05:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] LogisticLoss: 0.478840, auc: 0.804510, accuracy: 0.771642 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] LogisticLoss: 0.499838, auc: 0.775682, accuracy: 0.760527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:54<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] LogisticLoss: 0.474542, auc: 0.808790, accuracy: 0.774628 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] LogisticLoss: 0.501352, auc: 0.774144, accuracy: 0.758430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 647/647 [04:51<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] LogisticLoss: 0.470230, auc: 0.813006, accuracy: 0.777296 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 162/162 [00:23<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] LogisticLoss: 0.503749, auc: 0.772009, accuracy: 0.757615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 106/647 [00:48<04:06,  2.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2103385/687973337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mFRKT\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFRKT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfrkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFRKT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_exercise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_skill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_rasch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_rasch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfrkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/users/wyz/EduKTM/examples/RDKVMN+/FRKT.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset_name, seq_len, epoch, lr, lr_decay_step, lr_decay_rate)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             train_loss, train_auc, train_accuracy = train_one_epoch(self.frkt_net, optimizer, criterion,\n\u001b[0;32m--> 196\u001b[0;31m                                                                     self.batch_size, self.device, *train_data)\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Epoch %d] LogisticLoss: %.6f, auc: %.6f, accuracy: %.6f \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_auc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_train_auc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/users/wyz/EduKTM/examples/RDKVMN+/FRKT.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(net, optimizer, criterion, batch_size, device, s_data, a_data, e_data, at_data)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#seq_len<=200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m#clip_grad_norm_(net.parameters(), max_norm=0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jplab/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jplab/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from FRKT import FRKT\n",
    "frkt = FRKT(n_exercise, n_skill, batch_size, q_matrix, device=device, hidden_size=hidden_size, k_components=k_components, dropout=dropout, use_rasch=use_rasch)\n",
    "frkt.train(dataset_name, seq_len=seq_len, epoch=100, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(2023)\n",
    "\n",
    "import pickle\n",
    "def generate_q_matrix(path, n_skill, n_exercise):\n",
    "    with open(path, 'rb') as f:\n",
    "        problem2skill = pickle.load(f)\n",
    "        \n",
    "    q_matrix = np.zeros((n_exercise + 1, n_skill + 1))\n",
    "    for p,values in problem2skill.items():\n",
    "        for s in values:\n",
    "            q_matrix[p][s] = 1\n",
    "    return q_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exercise = 53091\n",
    "n_skill = 265 \n",
    "batch_size = 32\n",
    "hidden_size = 128\n",
    "k_components = 32\n",
    "dropout = 0.2\n",
    "use_rasch = True\n",
    "path = \"../../data/2012-2013-data-with-predictions-4-final/problem2skill.pickle\"\n",
    "q_matrix =  generate_q_matrix(path,n_skill,n_exercise)\n",
    "dataset_name = \"assistment2012\"\n",
    "seq_len = 200\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr=1e-3\n",
    "\n",
    "dataset_dir ={}\n",
    "dataset_dir[\"assistment2009\"] = \"2009_skill_builder_data_corrected_collapsed\"\n",
    "dataset_dir[\"assistment2012\"] = \"2012-2013-data-with-predictions-4-final\"\n",
    "dataset_dir[\"assistment2015\"] = \"2015_100_skill_builders_main_problems\"\n",
    "dataset_dir[\"assistment2017\"] = \"anonymized_full_release_competition_dataset\"\n",
    "dataset_dir[\"algebra2005\"] = \"algebra_2005_2006\"\n",
    "dataset_dir[\"statics\"] = \"statics\"\n",
    "dataset_dir[\"EdNet-KT1\"] = \"EdNet-Contents/contents\"\n",
    "\n",
    "import os \n",
    "\n",
    "saved_path = os.path.join(\"saved_model\",dataset_dir[dataset_name])\n",
    "model_path = os.path.join(saved_path, f\"model-seq_len{seq_len:03d}-lr{lr}-hidden_size{hidden_size:03d}-k{k_components}-use_rasch{use_rasch:01d}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import DATA\n",
    "from load_data_akt import DATA as DT_DATA             # 来自DTransformer的数据集\n",
    "from load_data_akt import PID_DATA as DT_PID_DATA\n",
    "\n",
    "data_dir = \"../../data/\"+dataset_dir[dataset_name]\n",
    "if dataset_name in [\"assistment2009\", \"assistment2012\", \"assistment2015\", \"assistment2017\",\"EdNet-KT1\",\"algebra2005\"]:\n",
    "    test_path = os.path.join(data_dir, \"test.txt\")      \n",
    "    dat = DATA(seqlen=seq_len, separate_char=',')\n",
    "    \n",
    "elif dataset_name in [\"statics\"]:\n",
    "    test_path = os.path.join(data_dir, \"test.txt\")\n",
    "    if n_exercise>0:\n",
    "        dat = DT_PID_DATA(seqlen=seq_len, separate_char=',')\n",
    "    else:\n",
    "        dat = DT_DATA(seqlen=seq_len, separate_char=',')\n",
    "else:\n",
    "    raise ValueError('ValueError: Unknown dataset! ')\n",
    "       \n",
    "test_data = dat.load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load parameters from saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_model/2012-2013-data-with-predictions-4-final/model-seq_len200-lr0.001-hidden_size128-k32-use_rasch1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 205/205 [00:28<00:00,  7.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5040420889854431, 0.7808201865626625, 0.75601051979285)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from FRKT import FRKT\n",
    "print(model_path)\n",
    "frkt = FRKT(n_exercise, n_skill, batch_size, q_matrix, device, hidden_size, k_components=k_components, dropout=dropout, use_rasch=use_rasch)\n",
    "frkt.load(model_path)\n",
    "frkt.eval(device, test_data)\n",
    "\n",
    "# 0.781332"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
